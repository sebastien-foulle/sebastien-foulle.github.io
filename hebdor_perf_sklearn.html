<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>  Performance d’un modele avec scikit-learn et scikit-plot  </title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

/* A workaround for https://github.com/jgm/pandoc/issues/4278 */
a.sourceLine {
  pointer-events: auto;
}

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link rel="stylesheet" href="hebdor_perf_sklearn_files/style.css" type="text/css" />





</head>

<body>




<section class="page-header">
<h1 class="title toc-ignore project-name"> <svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:60px;width:52.5px;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:gold;overflow:visible;position:relative;"><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z"/></svg> Performance d’un modele avec <em>scikit-learn</em> et <em>scikit-plot</em> <br></h1>
</section>


<div id="TOC" class="toc">
<div class="toc-box">
<h2 id="toc-title" class="toc-title">Table des matieres</h2>
<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#rappel-precision-f-score-optimal">Rappel, precision, F-score optimal</a></li>
<li><a href="#matrice-de-confusion">Matrice de confusion</a></li>
<li><a href="#auc-et-courbe-roc">AUC et courbe ROC</a></li>
</ul>
</div>
</div>

<section class="main-content">
<style>
.r{background-color:lightgrey !important;}
</style>
<div id="intro" class="section level1">
<h1>Introduction</h1>
<p>Le module <em>scikit-learn</em> permet d’obtenir facilement des indicteurs comme l’AUC ou le F-score, et avec <em>scikit-plot</em> il est facile de visualiser la courbe ROC ou la matroce de confusion.Petite demonstration sur le jeu de donnees qui suit.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># les donnees</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;otvPlots&quot;</span>)</span></code></pre></div>
<p>Ici le jeu de donnees est traite comme un echantillon test et on choisit directement un des champs numeriques de la table (la duree du dernier appel du client) comme score de la variable cible “y” recodee en 0/1. En effet ce seul champ est tres predicif de la cible (l’ouverture d’un compte a terme dans une banque).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_auc_score, roc_curve, plot_roc_curve, <span class="op">\</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>confusion_matrix, classification_report, precision_recall_curve</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scikitplot <span class="im">as</span> skplt</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_columns&#39;</span>, <span class="va">None</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>bank <span class="op">=</span> r.bankData</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>bank.rename(columns <span class="op">=</span> {<span class="st">&#39;duration&#39;</span>: <span class="st">&#39;score&#39;</span>}, inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>bank[<span class="st">&quot;cible&quot;</span>] <span class="op">=</span> bank[<span class="st">&#39;y&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x<span class="op">==</span><span class="st">&quot;yes&quot;</span> <span class="cf">else</span> <span class="dv">0</span>)</span></code></pre></div>
<p>On normalise le pseudo-score entre 0 et 1.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>bank[<span class="st">&quot;score&quot;</span>] <span class="op">=</span> scaler.fit_transform(bank[[<span class="st">&quot;score&quot;</span>]])</span></code></pre></div>
<p>Frequence de la modalite cible : 12%.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="sc">%.3f</span><span class="st">&quot;</span> <span class="op">%</span> bank[<span class="st">&quot;cible&quot;</span>].mean())</span></code></pre></div>
<pre><code>0.117</code></pre>
</div>
<div id="rappel-precision-f-score-optimal" class="section level1">
<h1>Rappel, precision, F-score optimal</h1>
<p>La courbe ROC, l’AUC, la sensibilite et la sensibilite ne dependent pas de la frequence de la modalite cible : on obtiendrait les memes valeurs (a alea pres) en equilibrant l’echantillon test. Dans le cas d’une cible rare, un modele avec une bonne sensibilite et specificite peut avoir une mauvaise precision, alors qu’une precision elevee impliquera une specificite elevee.</p>
<p>Ci-dessous une matrice de confusion avec une cible rare, des sensibilites et specifites elevees mais une mauvaise precision : la petite erreur sur la specificite couplee au grand volume de non-cibles suffit a faire de trop nombreux faux positifs qui entachent la precision du modele.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dtf <span class="op">=</span> pd.DataFrame({<span class="st">&#39;False&#39;</span>: [<span class="dv">5000</span>, <span class="dv">5</span>], <span class="st">&#39;True&#39;</span>: [<span class="dv">500</span>, <span class="dv">50</span>]})</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dtf.columns.name <span class="op">=</span> <span class="st">&quot;predit&quot;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>dtf.index.name <span class="op">=</span> <span class="st">&quot;reel&quot;</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>dtf</span></code></pre></div>
<pre><code>predit  False  True
reel               
0        5000   500
1           5    50</code></pre>
<p>C’est pourquoi il est plus interessant de suivre les 2 indicateurs suivants :</p>
<ul>
<li>la sensibilite (= rappel de la classe 1) : si elle est proche de 1, le modele identifie une bonne partie des veritables cibles</li>
<li>la precision : si elle est proche de 1, les cibles prevues par le modele sont majoritairement des veritables cibles. La precision est egale au lift multiplie par la frequence de la modalite cible.</li>
</ul>
<p>Le F-score se calcule a partir de ces indicateurs pour trouver un bon compromis entre leurs valeurs respectives. On cherche le seuil de F-score maximal, ici il est assez proche de la frequence de la modalite cible (12%).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>precisions, rappels, seuils <span class="op">=</span> precision_recall_curve(bank.cible, bank.score)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># precisions et rappels ont un point supplementaire final egal resp. a 1 et 0, sans seuil</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>precisions <span class="op">=</span> precisions[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>rappels <span class="op">=</span> rappels[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>condition <span class="op">=</span> rappels <span class="op">+</span> precisions <span class="op">&gt;</span> <span class="dv">0</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>precisions <span class="op">=</span> precisions[condition]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>rappels <span class="op">=</span> rappels[condition]</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>seuils <span class="op">=</span> seuils[condition]</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>f1_scores <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> rappels <span class="op">*</span> precisions<span class="op">/</span>(rappels <span class="op">+</span> precisions)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>val_seuil <span class="op">=</span> seuils[np.argmax(f1_scores)]</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Meilleur seuil : &quot;</span>, val_seuil)</span></code></pre></div>
<pre><code>Meilleur seuil :  0.09617730784871899</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Meilleur F1-Score : &quot;</span>, np.<span class="bu">max</span>(f1_scores))</span></code></pre></div>
<pre><code>Meilleur F1-Score :  0.4310790341263477</code></pre>
<p>La fonction suivant fournit differents indicateurs :</p>
<ul>
<li>recall = le rappel : selon la modalite concernee (1 ou 0), c’est la sensibilite ou la specificite</li>
<li>precision, f1-score : a ne regarder que pour la modalite cible 1</li>
</ul>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(bank.cible, bank.score <span class="op">&gt;=</span> val_seuil))</span></code></pre></div>
<pre><code>              precision    recall  f1-score   support

           0       0.93      0.91      0.92     39922
           1       0.41      0.46      0.43      5289

    accuracy                           0.86     45211
   macro avg       0.67      0.68      0.68     45211
weighted avg       0.87      0.86      0.86     45211</code></pre>
</div>
<div id="matrice-de-confusion" class="section level1">
<h1>Matrice de confusion</h1>
<p>La matrice de confusion proposee par <em>scikit-learn</em> est assez sommaire :</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(bank.cible, bank.score <span class="op">&gt;=</span> val_seuil))</span></code></pre></div>
<pre><code>[[36407  3515]
 [ 2870  2419]]</code></pre>
<p>La fonction <em>crosstab</em> donne un affichage bien plus parlant.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dtf_conf <span class="op">=</span> pd.DataFrame({<span class="st">&quot;cible&quot;</span> : <span class="bu">list</span>(bank.cible), <span class="st">&quot;prev&quot;</span>: bank.score <span class="op">&gt;=</span> val_seuil})</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.crosstab(dtf_conf.cible, dtf_conf.prev, rownames<span class="op">=</span>[<span class="st">&#39;reel&#39;</span>], colnames<span class="op">=</span>[<span class="st">&#39;predit&#39;</span>]))</span></code></pre></div>
<pre><code>predit  False  True 
reel                
0       36407   3515
1        2870   2419</code></pre>
<p>Avec <em>scikit-plot</em> on a une matrice de confusion plus visuelle, mais ca n’est vraiment utile que pour du multi-classe.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>skplt.metrics.plot_confusion_matrix(bank.cible, bank.score <span class="op">&gt;=</span> val_seuil)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="hebdor_perf_sklearn_files/figure-html/unnamed-chunk-10-1.png" width="500" height="400" style="display: block; margin: auto;" /></p>
</div>
<div id="auc-et-courbe-roc" class="section level1">
<h1>AUC et courbe ROC</h1>
<p>L’aire sous la courbe ROC :</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>val_auc <span class="op">=</span> roc_auc_score(bank.cible, bank.score)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>val_auc<span class="sc">: .3f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<pre><code> 0.808</code></pre>
<p>A l’aide des donnees fournies par la fonction <em>roc_curve</em> on peut realiser la courbe ROC a la main et positionner le seuil choisi.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>un_moins_spec, sens, seuil <span class="op">=</span> roc_curve(bank.cible, bank.score)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>recall_0 <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> un_moins_spec[<span class="bu">sum</span>(seuil<span class="op">&gt;</span>val_seuil)]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>recall_1 <span class="op">=</span> sens[<span class="bu">sum</span>(seuil<span class="op">&gt;</span>val_seuil)]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">7</span>, <span class="dv">5</span>))</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>sns.lineplot(un_moins_spec, sens, estimator<span class="op">=</span><span class="va">None</span>, color <span class="op">=</span> <span class="st">&quot;gold&quot;</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f&quot;courbe ROC d&#39;AUC </span><span class="sc">{</span><span class="bu">round</span>(val_auc,<span class="dv">2</span>)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>,<span class="dv">1</span>], [<span class="dv">0</span>,<span class="dv">1</span>], color <span class="op">=</span> <span class="st">&#39;navy&#39;</span>, linestyle <span class="op">=</span> <span class="st">&#39;--&#39;</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="dv">1</span> <span class="op">-</span> recall_0, recall_1,<span class="st">&#39;ro&#39;</span>,label<span class="op">=</span><span class="st">&#39;Seuil choisi&#39;</span>)<span class="op">;</span> plt.legend()<span class="op">;</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Taux faux positifs&#39;</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Taux vrais positifs&#39;</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&quot;lower right&quot;</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="hebdor_perf_sklearn_files/figure-html/unnamed-chunk-12-1.png" width="600px" height="400" style="display: block; margin: auto;" /></p>
<p>Avec <em>scikit-plot</em> la courbe ROC s’obtient tres facilement. Les macro et micro-moyennes n’ont d’interet que pour les modelisations avec &gt; 2 classes, ce qui n’est pas le cas ici.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>dtf <span class="op">=</span> pd.DataFrame({<span class="st">&quot;non&quot;</span>: <span class="dv">1</span> <span class="op">-</span> bank.score, <span class="st">&quot;oui&quot;</span>: bank.score})</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>skplt.metrics.plot_roc(bank.cible, dtf)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="hebdor_perf_sklearn_files/figure-html/unnamed-chunk-13-1.png" width="500" height="400" style="display: block; margin: auto;" /></p>
<p>La courbe de gain cumulee : au decile X elle fournit la part de la population cible totale qui se trouve dans les X 1ers deciles. En termes statistiques cette courbe fournit la sensibilite cumulee du modele. Cette courbe est beaucoup plus operationnelle que la courbe ROC, elle permet de choisir un seuil non pas a partir de choix theoriques (F-score) mais de criteres pratiques (quel est le cout de cibler X% de la population, pour quel retour sur investissement).</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>skplt.metrics.plot_cumulative_gain(bank.cible, dtf)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="hebdor_perf_sklearn_files/figure-html/unnamed-chunk-14-1.png" width="500" height="400" style="display: block; margin: auto;" /></p>
<p><a href="#intro"><strong>retour au debut du document</strong></a></p>
</div>
</section>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
